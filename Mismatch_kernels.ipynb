{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kernels import * \n",
    "from learning_models import *\n",
    "from tools import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time \n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "from autoreload import superreload\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_kernel(X, length):\n",
    "    all_sequence = {}\n",
    "    \n",
    "    for idx in range(len(X)):\n",
    "        data = X[idx]\n",
    "        for i in range(len(data)-length + 1):\n",
    "            seq1 = data[i:i+length]\n",
    "            if seq1 in all_sequence:\n",
    "                if idx in all_sequence[seq1]:\n",
    "                    all_sequence[seq1][idx] += 1\n",
    "                else:\n",
    "                    all_sequence[seq1][idx] = 1\n",
    "            else:\n",
    "                all_sequence[seq1] = {}\n",
    "                all_sequence[seq1][idx] = 1\n",
    "    \n",
    "    kernel = np.zeros((len(X), len(X)))\n",
    "    \n",
    "    for seq in all_sequence:\n",
    "        for key1 in all_sequence[seq]:\n",
    "            for key2 in all_sequence[seq]:\n",
    "                kernel[key1][key2] += all_sequence[seq][key1]*all_sequence[seq][key2]\n",
    "                \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_mismatch_kernel(X, lengths, mismatch, verbose = False):\n",
    "    \n",
    "    all_sequences_index = {}\n",
    "    id_last_seq = 0\n",
    "    for data in X:\n",
    "        for i in range(len(data)-lengths + 1):\n",
    "            seq = data[i:i+lengths]\n",
    "            if seq not in all_sequences_index:\n",
    "                all_sequences_index[seq] = id_last_seq\n",
    "                id_last_seq += 1\n",
    "\n",
    "    \n",
    "    vectors = np.zeros((len(X),len(all_sequences_index)))\n",
    "    \n",
    "    for idx in tqdm(range(len(X))):\n",
    "        data = X[idx]\n",
    "        for i in range(len(data)-lengths + 1):\n",
    "            seq = data[i:i+lengths]\n",
    "            vectors[idx, all_sequences_index[seq]] += 1\n",
    "            if mismatch >= 1:\n",
    "                for seq_mis in one_mismatch_away(seq):\n",
    "                    if seq_mis in all_sequences_index:\n",
    "                        vectors[idx, all_sequences_index[seq_mis]] += 1/2\n",
    "            if mismatch >= 2:\n",
    "                for seq_mis in two_mismatch_away(seq):\n",
    "                    if seq_mis in all_sequences_index:\n",
    "                        vectors[idx, all_sequences_index[seq_mis]] += 1/3\n",
    "     \n",
    "    if verbose:\n",
    "        print(all_sequences_index)\n",
    "        print('Embedding :')\n",
    "        print(vectors)\n",
    "    return np.dot(vectors,vectors.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_mismatch_away(s):\n",
    "    res = []\n",
    "    for i,letter in enumerate(s):\n",
    "        if letter not in ['A','T','C','G']:\n",
    "            print('Please use only letters in ATCG')\n",
    "        if letter != 'A':\n",
    "            res.append(str(s[:i]) + 'A' + str(s[i+1:]))\n",
    "        if letter != 'T':\n",
    "            res.append(str(s[:i]) + 'T' + str(s[i+1:]))\n",
    "        if letter != 'C':\n",
    "            res.append(str(s[:i]) + 'C' + str(s[i+1:]))\n",
    "        if letter != 'G':\n",
    "            res.append(str(s[:i]) + 'G' + str(s[i+1:]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_mismatch_away(s):\n",
    "    res = []\n",
    "    for a in one_mismatch_away(s):\n",
    "        for t in one_mismatch_away(a):\n",
    "            if t not in res and t != s and t not in one_mismatch_away(s):\n",
    "                res.append(t)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitResults(filename, y_pred_final):\n",
    "    '''\n",
    "    Creates, from a 1d array of final predicted values, a file named filename formated appropriately in order to make a\n",
    "    submission on the Kaggle platform.\n",
    "    '''\n",
    "    y = np.concatenate([y_pred_final[i] for i in [0,1,2]])\n",
    "    with open(\"data/submission/{}.csv\".format(filename), 'w') as f:\n",
    "        string = \"Id,Bound\\n\"\n",
    "        for j in range(0,3000):\n",
    "            string += str(j)+','+str(int(y[j]))+'\\n'\n",
    "        f.write(string)\n",
    "    print(\"----------------- Prediction written on {}.csv ---------------\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 6505.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.5   2.25  2.25  2.  ]\n",
      " [ 2.25  2.5   2.5   2.25]\n",
      " [ 2.25  2.5   2.5   2.25]\n",
      " [ 2.    2.25  2.25  2.5 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = ['TTCG',\n",
    "    'ATCG',\n",
    "    'ATCG',\n",
    "    'ATCA']\n",
    "m1 = embedding_mismatch_kernel(X,3,1, False)\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation to launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- File 0 read ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:45<00:00,  2.26s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.72it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Kernel 0 computed in 45.1355938911438 sec ------\n",
      "Best for file 0 :\n",
      "(0.29126326549087367, [1.0, 1.0])\n",
      "----- File 1 read ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:46<00:00,  2.34s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Kernel 1 computed in 46.8635458946228 sec ------\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "y_true_values = [0], y_pred_values = [0 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bed7c8ef6f48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mY_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_train_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlmdb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnb_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlmdb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnb_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best for file {} :\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/kernel/tools.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0my_pred_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     assert set(y_pred_values).issubset(set(y_true_values)), \"y_true_values = {}, y_pred_values = {}\".format(y_true_values,\n\u001b[0;32m--> 234\u001b[0;31m                                                                                                    y_pred_values)\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ys must have only 2 possible values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: y_true_values = [0], y_pred_values = [0 1]"
     ]
    }
   ],
   "source": [
    "y_pred_final = []\n",
    "length = [11,11,8]\n",
    "kernels = []\n",
    "nb_iter = 20\n",
    "lambdas = [np.logspace(-1.5, 0, 15, endpoint=True),\n",
    "           np.logspace(-2, -1, 15, endpoint=True),\n",
    "           np.logspace(-0.5, 1, 15, endpoint=True)]\n",
    "\n",
    "for file in [0,1,2]:\n",
    "    X_train = pd.read_csv(\"data/Xtr{}.csv\".format(file), sep=' ',header=None)[0].values.tolist()\n",
    "    Y_train = pd.read_csv(\"./data/Ytr{}.csv\".format(file), index_col=0)['Bound'].values\n",
    "    print(\"----- File {} read ------\".format(file))\n",
    "\n",
    "    res = {}\n",
    "    \n",
    "    for lmdb in lambdas[file]:\n",
    "        res[lmdb] = [0,0]\n",
    "\n",
    "    begin = time()\n",
    "    K_train = embedding_mismatch_kernel(X_train,length[file],2)\n",
    "    kernels.append(K_train)\n",
    "    end = time()\n",
    "    print(\"----- Kernel {} computed in {} sec ------\".format(file, end - begin))\n",
    "\n",
    "    \n",
    "    for i in tqdm(range(nb_iter)):\n",
    "        for lmdb in lambdas[file]:\n",
    "            X_train_c, X_test_c, Y_train_c, Y_test_c, K_train_c, K_test_c = K_train_test_split(X_train,Y_train,K_train,test_size=0.2)\n",
    "            Y_train_c.shape = (Y_train_c.shape[0])\n",
    "            Y_test_c.shape = (Y_test_c.shape[0])\n",
    "            Y_train_c.shape = (Y_train_c.shape[0])\n",
    "            model = SVM(lmbd=lmdb)\n",
    "            model.train(K_train_c, Y_train_c)\n",
    "            Y_test_pred = list(map(int,model.predict(K_test_c)))\n",
    "            Y_train_pred = list(map(int,model.predict(K_train_c)))\n",
    "            res[lmdb][1] += accuracy_score(Y_train_c, Y_train_pred)/nb_iter\n",
    "            res[lmdb][0] += accuracy_score(Y_test_c, Y_test_pred)/nb_iter\n",
    "\n",
    "    print(\"Best for file {} :\".format(file))\n",
    "    sorted_x = sorted(res.items(), key=operator.itemgetter(1))\n",
    "\n",
    "    print(sorted_x[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- File 0 read ------\n",
      "----- Kernel 0 computed in 3.0994415283203125e-06 sec ------\n",
      "----- File 0 predicted ------\n",
      "----- File 1 read ------\n",
      "----- Kernel 1 computed in 2.1457672119140625e-06 sec ------\n",
      "----- File 1 predicted ------\n",
      "----- File 2 read ------\n",
      "----- Kernel 2 computed in 2.1457672119140625e-06 sec ------\n",
      "----- File 2 predicted ------\n",
      "----------------- Prediction written on SixthSubmission.csv ---------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "y_pred_final = []\n",
    "length = [11,11,8]\n",
    "l = [0.1668, 0.0220, 1.3226]\n",
    "\n",
    "for file in [0,1,2]:\n",
    "    X_train = pd.read_csv(\"data/Xtr{}.csv\".format(file), sep=' ',header=None)[0].values.tolist()\n",
    "    Y_train = pd.read_csv(\"./data/Ytr{}.csv\".format(file), index_col=0)['Bound'].values\n",
    "    X_test = pd.read_csv(\"data/Xte{}.csv\".format(file), sep=' ',header=None)[0].values.tolist()\n",
    "\n",
    "    big_X = np.concatenate((X_train, X_test),axis=0)\n",
    "    \n",
    "    print(\"----- File {} read ------\".format(file))\n",
    "\n",
    "    res = []\n",
    "    if kernels_computed:\n",
    "        \n",
    "    begin = time()\n",
    "    big_K = embedding_mismatch_kernel(big_X,length[file],2)\n",
    "    end = time()\n",
    "    print(\"----- Kernel {} computed in {} sec ------\".format(file, end - begin))\n",
    "\n",
    "    K_train = big_K[:len(X_train),:len(X_train)]\n",
    "    K_test = big_K[len(X_train):,:len(X_train)]\n",
    "    \n",
    "    clf = SVM(lmbd=l[file], loss='squared_hinge')\n",
    "    clf.train(K_train, Y_train)\n",
    "    y_pred = clf.predict(K_test)\n",
    "    \n",
    "    y_pred_final.append(y_pred)\n",
    "\n",
    "    print(\"----- File {} predicted ------\".format(file))\n",
    "\n",
    "\n",
    "submitResults(\"SixthSubmission\", y_pred_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Travail sur le dataset 0:\n",
    "Mismatch 6-0 : lambda = 0.02712 score = 0.7575\n",
    "Mismatch 9-1 : lambda = 0.007742 score = 0.7692\n",
    "Mismatch 11-2 : lambda = 0.1668 score = 0.7713\n",
    "\n",
    "Travail sur le dataset 1:\n",
    "Mismatch 6-0 : lambda = 0.05994 score = 0.8825\n",
    "Mismatch 9-1 : lambda = 0.01584 score = 0.9050\n",
    "Mismatch 11-2 : lambda = 0.0220 score = 0.9075\n",
    "\n",
    "Travail sur le dataset 2:\n",
    "Mismatch 5-0 : lambda = 0.00774 score = 0.64225\n",
    "Mismatch 7-1 : lambda = 0.46415 score = 0.6652\n",
    "Mismatch 8-2 : lambda = 1.3226 score = 0.67175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 0\n",
    "X_train = pd.read_csv(\"data/Xtr{}.csv\".format(file), sep=' ',header=None)[0].values.tolist()\n",
    "Y_train = pd.read_csv(\"./data/Ytr{}.csv\".format(file), index_col=0)['Bound'].values\n",
    "X_train_c, X_test_c, Y_train_c, Y_test_c, K_train_c, K_test_c = K_train_test_split(X_train[:10],Y_train,K_train,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
