{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from kernels import * \n",
    "from learning_models import *\n",
    "from tools import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time \n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "from autoreload import superreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel = pd.read_csv('Kernel_MisMatch_5_1.csv', index_col=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"Data/Train/Ytr0.csv\", index_col=0)['Bound'].values\n",
    "#dataY = pd.read_csv(\"Data/Train/Ytr0.csv\", index_col=0)\n",
    "#y = dataY['Bound'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = load_and_transform(\"Data/Train/Xtr0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = [0.001,0.01,0.05,0.1,1,10,100,1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVM(loss='hinge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 With Kernel unmodified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [04:29<00:00, 26.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.05\n",
      "\tTrain accuracy score : 0.763\n",
      "\tTest accuracy score : 0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [04:13<00:00, 25.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.001\n",
      "\tTrain accuracy score : 0.770\n",
      "\tTest accuracy score : 0.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 With Kernel taking into account the bias (1 added to every entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [04:58<00:00, 29.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.05\n",
      "\tTrain accuracy score : 0.754\n",
      "\tTest accuracy score : 0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [04:37<00:00, 27.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.001\n",
      "\tTrain accuracy score : 0.769\n",
      "\tTest accuracy score : 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Squared Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVM(loss='squared_hinge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 With Kernel unmodified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [01:25<00:00,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.05\n",
      "\tTrain accuracy score : 0.837\n",
      "\tTest accuracy score : 0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [01:08<00:00,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.05\n",
      "\tTrain accuracy score : 0.775\n",
      "\tTest accuracy score : 0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 With Kernel taking into account the bias (1 added to every entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [01:18<00:00,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 1.0\n",
      "\tTrain accuracy score : 0.781\n",
      "\tTest accuracy score : 0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [01:08<00:00,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.01\n",
      "\tTrain accuracy score : 0.788\n",
      "\tTest accuracy score : 0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KRR Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "krr = KRR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. With Kernel unmodified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [00:06<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.1 and threshold = 0.5\n",
      "\tTrain accuracy score : 0.793\n",
      "\tTest accuracy score : 0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(krr,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=False, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [00:06<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.001 and threshold = 0.5\n",
      "\tTrain accuracy score : 0.839\n",
      "\tTest accuracy score : 0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(krr,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=True, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. With Kernel taking into account the bias (1 added to every entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.05 and threshold = 0.5\n",
      "\tTrain accuracy score : 0.826\n",
      "\tTest accuracy score : 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(krr,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=False, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [00:06<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.001 and threshold = 0.5\n",
      "\tTrain accuracy score : 0.838\n",
      "\tTest accuracy score : 0.570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(krr,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=True, binary=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
