{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernels import * \n",
    "from learning_models import *\n",
    "from tools import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time \n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "from autoreload import superreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_kernel(X, length):\n",
    "    all_sequence = {}\n",
    "    \n",
    "    for idx in range(len(X)):\n",
    "        data = X[idx]\n",
    "        for i in range(len(data)-length + 1):\n",
    "            seq1 = data[i:i+length]\n",
    "            if seq1 in all_sequence:\n",
    "                if idx in all_sequence[seq1]:\n",
    "                    all_sequence[seq1][idx] += 1\n",
    "                else:\n",
    "                    all_sequence[seq1][idx] = 1\n",
    "            else:\n",
    "                all_sequence[seq1] = {}\n",
    "                all_sequence[seq1][idx] = 1\n",
    "    \n",
    "    kernel = np.zeros((len(X), len(X)))\n",
    "    \n",
    "    for seq in all_sequence:\n",
    "        for key1 in all_sequence[seq]:\n",
    "            for key2 in all_sequence[seq]:\n",
    "                kernel[key1][key2] += all_sequence[seq][key1]*all_sequence[seq][key2]\n",
    "                \n",
    "    \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = pd.read_csv('Kernel_MisMatch_5_1.csv', index_col=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/Xtr2.csv\", header=None)[0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.6 s, sys: 141 ms, total: 28.8 s\n",
      "Wall time: 29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kernel = spectrum_kernel(data,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"./data/Ytr2.csv\", index_col=0)['Bound'].values\n",
    "#dataY = pd.read_csv(\"Data/Train/Ytr0.csv\", index_col=0)\n",
    "#y = dataY['Bound'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ..., 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_and_transform(\"./data/Xtr0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [0.001,0.01,0.05,0.1,1,10,100,1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM(loss='hinge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1e-06 ---------\n",
      "0.56\n",
      "0.58125\n",
      "------- 1e-05 ---------\n",
      "0.61\n",
      "0.625625\n",
      "------- 0.0001 ---------\n",
      "0.54\n",
      "0.60125\n",
      "------- 0.001 ---------\n",
      "0.5675\n",
      "0.725\n",
      "------- 0.01 ---------\n",
      "0.605\n",
      "0.825\n",
      "------- 0.05 ---------\n",
      "0.635\n",
      "0.87625\n",
      "------- 0.1 ---------\n",
      "0.58\n",
      "0.90375\n",
      "------- 1 ---------\n",
      "0.5975\n",
      "0.9725\n",
      "------- 10 ---------\n",
      "0.58\n",
      "1.0\n",
      "------- 100 ---------\n",
      "0.575\n",
      "1.0\n",
      "------- 1000 ---------\n",
      "0.595\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "for c in [1e-6,1e-5,1e-4,0.001,0.01,0.05,0.1,1,10,100,1000]:\n",
    "    print(\"------- {} ---------\".format(c))\n",
    "    svc = SVC(C = c, kernel='precomputed')\n",
    "    \n",
    "    K_norm = normalize_kernel(kernel)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, K_train, K_test = train_test_split(X,y,kernel,test_size=0.2,\n",
    "                                                                                     verbose=False)\n",
    "    svc.fit(K_train, y_train)\n",
    "\n",
    "    y_pred = svc.predict(K_test)\n",
    "    y_pred_t = svc.predict(K_train)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(accuracy_score(y_train, y_pred_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 With Kernel unmodified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [04:38<00:00, 27.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.1\n",
      "\tTrain accuracy score : 0.788\n",
      "\tTest accuracy score : 0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg Training Score</th>\n",
       "      <th>avg Testing Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>0.936375</td>\n",
       "      <td>0.59875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.866375</td>\n",
       "      <td>0.61025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.050</th>\n",
       "      <td>0.814312</td>\n",
       "      <td>0.63400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.788312</td>\n",
       "      <td>0.63850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.675875</td>\n",
       "      <td>0.61000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.000</th>\n",
       "      <td>0.674813</td>\n",
       "      <td>0.60800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.000</th>\n",
       "      <td>0.674813</td>\n",
       "      <td>0.60825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000.000</th>\n",
       "      <td>0.674812</td>\n",
       "      <td>0.60825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg Training Score  avg Testing Score\n",
       "0.001               0.936375            0.59875\n",
       "0.010               0.866375            0.61025\n",
       "0.050               0.814312            0.63400\n",
       "0.100               0.788312            0.63850\n",
       "1.000               0.675875            0.61000\n",
       "10.000              0.674813            0.60800\n",
       "100.000             0.674813            0.60825\n",
       "1000.000            0.674812            0.60825"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_kernel = normalize_kernel(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.52899877  0.52787922 ...,  0.54665661  0.54742772\n",
      "  0.52422398]\n"
     ]
    }
   ],
   "source": [
    "print(N_kernel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [04:13<00:00, 25.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.001\n",
      "\tTrain accuracy score : 0.770\n",
      "\tTest accuracy score : 0.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 With Kernel taking into account the bias (1 added to every entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [04:58<00:00, 29.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.05\n",
      "\tTrain accuracy score : 0.754\n",
      "\tTest accuracy score : 0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [04:37<00:00, 27.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.001\n",
      "\tTrain accuracy score : 0.769\n",
      "\tTest accuracy score : 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Squared Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVM(loss='squared_hinge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 With Kernel unmodified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [01:25<00:00,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.05\n",
      "\tTrain accuracy score : 0.837\n",
      "\tTest accuracy score : 0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [01:08<00:00,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.05\n",
      "\tTrain accuracy score : 0.775\n",
      "\tTest accuracy score : 0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 With Kernel taking into account the bias (1 added to every entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [01:18<00:00,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 1.0\n",
      "\tTrain accuracy score : 0.781\n",
      "\tTest accuracy score : 0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [01:08<00:00,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.01\n",
      "\tTrain accuracy score : 0.788\n",
      "\tTest accuracy score : 0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(svm,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KRR Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "krr = KRR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. With Kernel unmodified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [00:06<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.1 and threshold = 0.5\n",
      "\tTrain accuracy score : 0.793\n",
      "\tTest accuracy score : 0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(krr,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=False, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [00:06<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.001 and threshold = 0.5\n",
      "\tTrain accuracy score : 0.839\n",
      "\tTest accuracy score : 0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(krr,X,y,kernel, lambdas=lambdas, n_validations=10, normalize=True, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. With Kernel taking into account the bias (1 added to every entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.05 and threshold = 0.5\n",
      "\tTrain accuracy score : 0.826\n",
      "\tTest accuracy score : 0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(krr,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=False, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% of validation rounds: 100%|██████████| 10/10 [00:06<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximal Testing Accuracy Score obtained with Lambda = 0.001 and threshold = 0.5\n",
      "\tTrain accuracy score : 0.838\n",
      "\tTest accuracy score : 0.570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = evaluate_model(krr,X,y,kernel+1, lambdas=lambdas, n_validations=10, normalize=True, binary=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
